model_dir: "../models/rec_model/best"
train_data_path: "../../Data/Beauty/FT_data/beauty_processed/cot_data/train.json"
val_data_path: "../../Data/Beauty/FT_data/beauty_processed/cot_data/val.json"
special_tokens_path: "../../Data/Beauty/FT_data/beauty/special_tokens.json"

per_device_train_batch_size: 1 
gradient_accumulation_steps: 8 
per_device_eval_batch_size: 1 

num_train_epochs: 1 
gradient_checkpointing: True 
bf16: True 
deepspeed: ./ds_zero2.json 
output_dir: ../models/cot_model
logging_dir: ../logs/train_cot_log
logging_steps: 1 
eval_strategy: "no" 
eval_on_start: False 
save_strategy: "epoch" 
save_total_limit: 1 


load_best_model_at_end: False 
optim: adamw_torch 
learning_rate: 1.0e-5 
warmup_ratio: 0.1 
weight_decay: 0.01 
adam_beta1: 0.9 
adam_beta2: 0.999 
adam_epsilon: 1.0e-8 
max_grad_norm: 1.0 
dataloader_num_workers: 4 
remove_unused_columns: False

lora_r: 128
lora_alpha: 128
lora_dropout: 0.05
lora_target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]