align_model_path: "../models/align_model/best"
train_data_path: "../data/beauty_processed/rec_data/train.json"
val_data_path: "../data/beauty_processed/rec_data/val.json"
special_tokens_path: "../data/beauty/special_tokens.json"

per_device_train_batch_size: 1
gradient_accumulation_steps: 8
per_device_eval_batch_size: 1

num_train_epochs: 6
gradient_checkpointing: True
bf16: True
deepspeed: ./ds_zero2.json
output_dir: ../models/rec_model
logging_dir: ../logs/train_rec_log
logging_steps: 10
eval_strategy: epoch
eval_on_start: False
save_strategy: epoch
save_total_limit: 10
metric_for_best_model: eval_loss
greater_is_better: False
load_best_model_at_end: True
optim: adamw_torch
learning_rate: 1.0e-5
warmup_ratio: 0.1
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1.0e-8
max_grad_norm: 1.0
dataloader_num_workers: 4
remove_unused_columns: False

lora_r: 128
lora_alpha: 128
lora_dropout: 0.05
lora_target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]